{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642794957.2892046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 1, 21, 19, 56, 31, 18823)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtnow=dt.datetime.fromtimestamp(tm.time())\n",
    "dtnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta =dt.timedelta(days=100)\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 1, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today=dt.date.today()\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class person:\n",
    "    department ='school of information'\n",
    "    \n",
    "    def set_nam(self,new_name):\n",
    "        self.name=new_name\n",
    "    def set_location(self,new_location):\n",
    "        self.location=new_location\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    def get_location(self):\n",
    "        return self.location\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map()  in python is like for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 10, 10, 30]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store1=[10,20,30,40,50]\n",
    "store2=[30,85,10,10,30]\n",
    "cheapest= map(min,store1,store2)\n",
    "list(cheapest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#array are displ;ayed as a list of list \n",
    "a= np.array([1,2,3])\n",
    "print (a)\n",
    "# we can print the dimension of the array\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [4 5 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we pass in a list of list in numpy array, we crate amutlti dimesntional array \n",
    "b=np.array([[1,2,3],[1,2,3],[4,5,6]])\n",
    "print(b)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the typr of items \n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 3. ],\n",
       "       [0.1, 2. , 3. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float one\n",
    "c= np.array([[1,2,3],[0.1,2,3]])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# fill with zeors\n",
    "d=np.zeros((2,3))\n",
    "print(d)\n",
    "e=np.ones((2,3))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89451667, 0.73297228, 0.07606854],\n",
       "       [0.27833434, 0.02294123, 0.5146201 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2,3)\n",
    "# create ranodm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42,\n",
       "       44, 46, 48])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sequnce of number in array\n",
    "f=np.arange(10,50,2)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
       "       0.71428571, 0.85714286, 1.        , 1.14285714, 1.28571429,\n",
       "       1.42857143, 1.57142857, 1.71428571, 1.85714286, 2.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequnce of float\n",
    "np.linspace(0,2,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arithmetic operators on array apply elemtwise\n",
    "a=np.array([1,2,3,4])\n",
    "b=np.array([2,3,4,5])\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.66666667, 0.75      , 0.8       ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 4],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.array([[1,1],[0,1]])\n",
    "B=np.array([[2,0],[3,4]])\n",
    "A*B\n",
    "# @ is dot produnt\n",
    "A@B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.2  4.   6. ]\n",
      " [94.  10.  12. ]]\n"
     ]
    }
   ],
   "source": [
    "# upcasting \n",
    "array1=np.array([[1,2,3],[47,5,6]])\n",
    "array2=np.array([[1.2,2,3],[47,5,6]])\n",
    "\n",
    "print(array1+array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexing slicing and iterating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,3,4,5])\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2],[1,2],[1,58]])\n",
    "a[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 58])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([a[0,0],a[1,1],a[2,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(a[[0,1,2],[0,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False  True]]\n"
     ]
    }
   ],
   "source": [
    "print(a>5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58]\n"
     ]
    }
   ],
   "source": [
    "print(a[a>5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slicing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# to slice used :\n",
    "a= np.array([1,2,3,4,5,6])\n",
    "print(a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "print(a[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# muti demison\n",
    "a=np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2,1:3]\n",
    "# first is for slecte row, second is for select collumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is importance to realize trhat aslice of an array is aview inbto the same data, this is called oassubng by reference. so modifyng the sub array will consequently modifu the original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 50,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_array=a[:2,1:3]\n",
    "sub_array[0,0]=50\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying numpy with datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4  ,  0.7  ,  0.   , ...,  0.56 ,  9.4  ,  5.   ],\n",
       "       [ 7.8  ,  0.88 ,  0.   , ...,  0.68 ,  9.8  ,  5.   ],\n",
       "       [ 7.8  ,  0.76 ,  0.04 , ...,  0.65 ,  9.8  ,  5.   ],\n",
       "       ...,\n",
       "       [ 6.3  ,  0.51 ,  0.13 , ...,  0.75 , 11.   ,  6.   ],\n",
       "       [ 5.9  ,  0.645,  0.12 , ...,  0.71 , 10.2  ,  5.   ],\n",
       "       [ 6.   ,  0.31 ,  0.47 , ...,  0.66 , 11.   ,  6.   ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines =np.genfromtxt(\"winequality-red.csv\",delimiter=\";\",skip_header=1)\n",
    "wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one interger 0 for slicing:  [7.4 7.8 7.8 ... 6.3 5.9 6. ]\n"
     ]
    }
   ],
   "source": [
    "print(\"one interger 0 for slicing: \",wines[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to 1 for sling [[7.4]\n",
      " [7.8]\n",
      " [7.8]\n",
      " ...\n",
      " [6.3]\n",
      " [5.9]\n",
      " [6. ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"0 to 1 for sling\",wines[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4  , 0.7  , 0.   ],\n",
       "       [7.8  , 0.88 , 0.   ],\n",
       "       [7.8  , 0.76 , 0.04 ],\n",
       "       ...,\n",
       "       [6.3  , 0.51 , 0.13 ],\n",
       "       [5.9  , 0.645, 0.12 ],\n",
       "       [6.   , 0.31 , 0.47 ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4  , 0.   , 0.076],\n",
       "       [7.8  , 0.   , 0.098],\n",
       "       [7.8  , 0.04 , 0.092],\n",
       "       ...,\n",
       "       [6.3  , 0.13 , 0.076],\n",
       "       [5.9  , 0.12 , 0.075],\n",
       "       [6.   , 0.47 , 0.067]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,[0,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6360225140712945"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(  1, 337, 118, 4, 4.5, 4.5, 9.65, 1, 0.92),\n",
       "       (  2, 324, 107, 4, 4. , 4.5, 8.87, 1, 0.76),\n",
       "       (  3, 316, 104, 3, 3. , 3.5, 8.  , 1, 0.72),\n",
       "       (  4, 322, 110, 3, 3.5, 2.5, 8.67, 1, 0.8 ),\n",
       "       (  5, 314, 103, 2, 2. , 3. , 8.21, 0, 0.65),\n",
       "       (  6, 330, 115, 5, 4.5, 3. , 9.34, 1, 0.9 ),\n",
       "       (  7, 321, 109, 3, 3. , 4. , 8.2 , 1, 0.75),\n",
       "       (  8, 308, 101, 2, 3. , 4. , 7.9 , 0, 0.68),\n",
       "       (  9, 302, 102, 1, 2. , 1.5, 8.  , 0, 0.5 ),\n",
       "       ( 10, 323, 108, 3, 3.5, 3. , 8.6 , 0, 0.45),\n",
       "       ( 11, 325, 106, 3, 3.5, 4. , 8.4 , 1, 0.52),\n",
       "       ( 12, 327, 111, 4, 4. , 4.5, 9.  , 1, 0.84),\n",
       "       ( 13, 328, 112, 4, 4. , 4.5, 9.1 , 1, 0.78),\n",
       "       ( 14, 307, 109, 3, 4. , 3. , 8.  , 1, 0.62),\n",
       "       ( 15, 311, 104, 3, 3.5, 2. , 8.2 , 1, 0.61),\n",
       "       ( 16, 314, 105, 3, 3.5, 2.5, 8.3 , 0, 0.54),\n",
       "       ( 17, 317, 107, 3, 4. , 3. , 8.7 , 0, 0.66),\n",
       "       ( 18, 319, 106, 3, 4. , 3. , 8.  , 1, 0.65),\n",
       "       ( 19, 318, 110, 3, 4. , 3. , 8.8 , 0, 0.63),\n",
       "       ( 20, 303, 102, 3, 3.5, 3. , 8.5 , 0, 0.62),\n",
       "       ( 21, 312, 107, 3, 3. , 2. , 7.9 , 1, 0.64),\n",
       "       ( 22, 325, 114, 4, 3. , 2. , 8.4 , 0, 0.7 ),\n",
       "       ( 23, 328, 116, 5, 5. , 5. , 9.5 , 1, 0.94),\n",
       "       ( 24, 334, 119, 5, 5. , 4.5, 9.7 , 1, 0.95),\n",
       "       ( 25, 336, 119, 5, 4. , 3.5, 9.8 , 1, 0.97),\n",
       "       ( 26, 340, 120, 5, 4.5, 4.5, 9.6 , 1, 0.94),\n",
       "       ( 27, 322, 109, 5, 4.5, 3.5, 8.8 , 0, 0.76),\n",
       "       ( 28, 298,  98, 2, 1.5, 2.5, 7.5 , 1, 0.44),\n",
       "       ( 29, 295,  93, 1, 2. , 2. , 7.2 , 0, 0.46),\n",
       "       ( 30, 310,  99, 2, 1.5, 2. , 7.3 , 0, 0.54),\n",
       "       ( 31, 300,  97, 2, 3. , 3. , 8.1 , 1, 0.65),\n",
       "       ( 32, 327, 103, 3, 4. , 4. , 8.3 , 1, 0.74),\n",
       "       ( 33, 338, 118, 4, 3. , 4.5, 9.4 , 1, 0.91),\n",
       "       ( 34, 340, 114, 5, 4. , 4. , 9.6 , 1, 0.9 ),\n",
       "       ( 35, 331, 112, 5, 4. , 5. , 9.8 , 1, 0.94),\n",
       "       ( 36, 320, 110, 5, 5. , 5. , 9.2 , 1, 0.88),\n",
       "       ( 37, 299, 106, 2, 4. , 4. , 8.4 , 0, 0.64),\n",
       "       ( 38, 300, 105, 1, 1. , 2. , 7.8 , 0, 0.58),\n",
       "       ( 39, 304, 105, 1, 3. , 1.5, 7.5 , 0, 0.52),\n",
       "       ( 40, 307, 108, 2, 4. , 3.5, 7.7 , 0, 0.48),\n",
       "       ( 41, 308, 110, 3, 3.5, 3. , 8.  , 1, 0.46),\n",
       "       ( 42, 316, 105, 2, 2.5, 2.5, 8.2 , 1, 0.49),\n",
       "       ( 43, 313, 107, 2, 2.5, 2. , 8.5 , 1, 0.53),\n",
       "       ( 44, 332, 117, 4, 4.5, 4. , 9.1 , 0, 0.87),\n",
       "       ( 45, 326, 113, 5, 4.5, 4. , 9.4 , 1, 0.91),\n",
       "       ( 46, 322, 110, 5, 5. , 4. , 9.1 , 1, 0.88),\n",
       "       ( 47, 329, 114, 5, 4. , 5. , 9.3 , 1, 0.86),\n",
       "       ( 48, 339, 119, 5, 4.5, 4. , 9.7 , 0, 0.89),\n",
       "       ( 49, 321, 110, 3, 3.5, 5. , 8.85, 1, 0.82),\n",
       "       ( 50, 327, 111, 4, 3. , 4. , 8.4 , 1, 0.78),\n",
       "       ( 51, 313,  98, 3, 2.5, 4.5, 8.3 , 1, 0.76),\n",
       "       ( 52, 312, 100, 2, 1.5, 3.5, 7.9 , 1, 0.56),\n",
       "       ( 53, 334, 116, 4, 4. , 3. , 8.  , 1, 0.78),\n",
       "       ( 54, 324, 112, 4, 4. , 2.5, 8.1 , 1, 0.72),\n",
       "       ( 55, 322, 110, 3, 3. , 3.5, 8.  , 0, 0.7 ),\n",
       "       ( 56, 320, 103, 3, 3. , 3. , 7.7 , 0, 0.64),\n",
       "       ( 57, 316, 102, 3, 2. , 3. , 7.4 , 0, 0.64),\n",
       "       ( 58, 298,  99, 2, 4. , 2. , 7.6 , 0, 0.46),\n",
       "       ( 59, 300,  99, 1, 3. , 2. , 6.8 , 1, 0.36),\n",
       "       ( 60, 311, 104, 2, 2. , 2. , 8.3 , 0, 0.42),\n",
       "       ( 61, 309, 100, 2, 3. , 3. , 8.1 , 0, 0.48),\n",
       "       ( 62, 307, 101, 3, 4. , 3. , 8.2 , 0, 0.47),\n",
       "       ( 63, 304, 105, 2, 3. , 3. , 8.2 , 1, 0.54),\n",
       "       ( 64, 315, 107, 2, 4. , 3. , 8.5 , 1, 0.56),\n",
       "       ( 65, 325, 111, 3, 3. , 3.5, 8.7 , 0, 0.52),\n",
       "       ( 66, 325, 112, 4, 3.5, 3.5, 8.92, 0, 0.55),\n",
       "       ( 67, 327, 114, 3, 3. , 3. , 9.02, 0, 0.61),\n",
       "       ( 68, 316, 107, 2, 3.5, 3.5, 8.64, 1, 0.57),\n",
       "       ( 69, 318, 109, 3, 3.5, 4. , 9.22, 1, 0.68),\n",
       "       ( 70, 328, 115, 4, 4.5, 4. , 9.16, 1, 0.78),\n",
       "       ( 71, 332, 118, 5, 5. , 5. , 9.64, 1, 0.94),\n",
       "       ( 72, 336, 112, 5, 5. , 5. , 9.76, 1, 0.96),\n",
       "       ( 73, 321, 111, 5, 5. , 5. , 9.45, 1, 0.93),\n",
       "       ( 74, 314, 108, 4, 4.5, 4. , 9.04, 1, 0.84),\n",
       "       ( 75, 314, 106, 3, 3. , 5. , 8.9 , 0, 0.74),\n",
       "       ( 76, 329, 114, 2, 2. , 4. , 8.56, 1, 0.72),\n",
       "       ( 77, 327, 112, 3, 3. , 3. , 8.72, 1, 0.74),\n",
       "       ( 78, 301,  99, 2, 3. , 2. , 8.22, 0, 0.64),\n",
       "       ( 79, 296,  95, 2, 3. , 2. , 7.54, 1, 0.44),\n",
       "       ( 80, 294,  93, 1, 1.5, 2. , 7.36, 0, 0.46),\n",
       "       ( 81, 312, 105, 3, 2. , 3. , 8.02, 1, 0.5 ),\n",
       "       ( 82, 340, 120, 4, 5. , 5. , 9.5 , 1, 0.96),\n",
       "       ( 83, 320, 110, 5, 5. , 4.5, 9.22, 1, 0.92),\n",
       "       ( 84, 322, 115, 5, 4. , 4.5, 9.36, 1, 0.92),\n",
       "       ( 85, 340, 115, 5, 4.5, 4.5, 9.45, 1, 0.94),\n",
       "       ( 86, 319, 103, 4, 4.5, 3.5, 8.66, 0, 0.76),\n",
       "       ( 87, 315, 106, 3, 4.5, 3.5, 8.42, 0, 0.72),\n",
       "       ( 88, 317, 107, 2, 3.5, 3. , 8.28, 0, 0.66),\n",
       "       ( 89, 314, 108, 3, 4.5, 3.5, 8.14, 0, 0.64),\n",
       "       ( 90, 316, 109, 4, 4.5, 3.5, 8.76, 1, 0.74),\n",
       "       ( 91, 318, 106, 2, 4. , 4. , 7.92, 1, 0.64),\n",
       "       ( 92, 299,  97, 3, 5. , 3.5, 7.66, 0, 0.38),\n",
       "       ( 93, 298,  98, 2, 4. , 3. , 8.03, 0, 0.34),\n",
       "       ( 94, 301,  97, 2, 3. , 3. , 7.88, 1, 0.44),\n",
       "       ( 95, 303,  99, 3, 2. , 2.5, 7.66, 0, 0.36),\n",
       "       ( 96, 304, 100, 4, 1.5, 2.5, 7.84, 0, 0.42),\n",
       "       ( 97, 306, 100, 2, 3. , 3. , 8.  , 0, 0.48),\n",
       "       ( 98, 331, 120, 3, 4. , 4. , 8.96, 1, 0.86),\n",
       "       ( 99, 332, 119, 4, 5. , 4.5, 9.24, 1, 0.9 ),\n",
       "       (100, 323, 113, 3, 4. , 4. , 8.88, 1, 0.79),\n",
       "       (101, 322, 107, 3, 3.5, 3.5, 8.46, 1, 0.71),\n",
       "       (102, 312, 105, 2, 2.5, 3. , 8.12, 0, 0.64),\n",
       "       (103, 314, 106, 2, 4. , 3.5, 8.25, 0, 0.62),\n",
       "       (104, 317, 104, 2, 4.5, 4. , 8.47, 0, 0.57),\n",
       "       (105, 326, 112, 3, 3.5, 3. , 9.05, 1, 0.74),\n",
       "       (106, 316, 110, 3, 4. , 4.5, 8.78, 1, 0.69),\n",
       "       (107, 329, 111, 4, 4.5, 4.5, 9.18, 1, 0.87),\n",
       "       (108, 338, 117, 4, 3.5, 4.5, 9.46, 1, 0.91),\n",
       "       (109, 331, 116, 5, 5. , 5. , 9.38, 1, 0.93),\n",
       "       (110, 304, 103, 5, 5. , 4. , 8.64, 0, 0.68),\n",
       "       (111, 305, 108, 5, 3. , 3. , 8.48, 0, 0.61),\n",
       "       (112, 321, 109, 4, 4. , 4. , 8.68, 1, 0.69),\n",
       "       (113, 301, 107, 3, 3.5, 3.5, 8.34, 1, 0.62),\n",
       "       (114, 320, 110, 2, 4. , 3.5, 8.56, 0, 0.72),\n",
       "       (115, 311, 105, 3, 3.5, 3. , 8.45, 1, 0.59),\n",
       "       (116, 310, 106, 4, 4.5, 4.5, 9.04, 1, 0.66),\n",
       "       (117, 299, 102, 3, 4. , 3.5, 8.62, 0, 0.56),\n",
       "       (118, 290, 104, 4, 2. , 2.5, 7.46, 0, 0.45),\n",
       "       (119, 296,  99, 2, 3. , 3.5, 7.28, 0, 0.47),\n",
       "       (120, 327, 104, 5, 3. , 3.5, 8.84, 1, 0.71),\n",
       "       (121, 335, 117, 5, 5. , 5. , 9.56, 1, 0.94),\n",
       "       (122, 334, 119, 5, 4.5, 4.5, 9.48, 1, 0.94),\n",
       "       (123, 310, 106, 4, 1.5, 2.5, 8.36, 0, 0.57),\n",
       "       (124, 308, 108, 3, 3.5, 3.5, 8.22, 0, 0.61),\n",
       "       (125, 301, 106, 4, 2.5, 3. , 8.47, 0, 0.57),\n",
       "       (126, 300, 100, 3, 2. , 3. , 8.66, 1, 0.64),\n",
       "       (127, 323, 113, 3, 4. , 3. , 9.32, 1, 0.85),\n",
       "       (128, 319, 112, 3, 2.5, 2. , 8.71, 1, 0.78),\n",
       "       (129, 326, 112, 3, 3.5, 3. , 9.1 , 1, 0.84),\n",
       "       (130, 333, 118, 5, 5. , 5. , 9.35, 1, 0.92),\n",
       "       (131, 339, 114, 5, 4. , 4.5, 9.76, 1, 0.96),\n",
       "       (132, 303, 105, 5, 5. , 4.5, 8.65, 0, 0.77),\n",
       "       (133, 309, 105, 5, 3.5, 3.5, 8.56, 0, 0.71),\n",
       "       (134, 323, 112, 5, 4. , 4.5, 8.78, 0, 0.79),\n",
       "       (135, 333, 113, 5, 4. , 4. , 9.28, 1, 0.89),\n",
       "       (136, 314, 109, 4, 3.5, 4. , 8.77, 1, 0.82),\n",
       "       (137, 312, 103, 3, 5. , 4. , 8.45, 0, 0.76),\n",
       "       (138, 316, 100, 2, 1.5, 3. , 8.16, 1, 0.71),\n",
       "       (139, 326, 116, 2, 4.5, 3. , 9.08, 1, 0.8 ),\n",
       "       (140, 318, 109, 1, 3.5, 3.5, 9.12, 0, 0.78),\n",
       "       (141, 329, 110, 2, 4. , 3. , 9.15, 1, 0.84),\n",
       "       (142, 332, 118, 2, 4.5, 3.5, 9.36, 1, 0.9 ),\n",
       "       (143, 331, 115, 5, 4. , 3.5, 9.44, 1, 0.92),\n",
       "       (144, 340, 120, 4, 4.5, 4. , 9.92, 1, 0.97),\n",
       "       (145, 325, 112, 2, 3. , 3.5, 8.96, 1, 0.8 ),\n",
       "       (146, 320, 113, 2, 2. , 2.5, 8.64, 1, 0.81),\n",
       "       (147, 315, 105, 3, 2. , 2.5, 8.48, 0, 0.75),\n",
       "       (148, 326, 114, 3, 3. , 3. , 9.11, 1, 0.83),\n",
       "       (149, 339, 116, 4, 4. , 3.5, 9.8 , 1, 0.96),\n",
       "       (150, 311, 106, 2, 3.5, 3. , 8.26, 1, 0.79),\n",
       "       (151, 334, 114, 4, 4. , 4. , 9.43, 1, 0.93),\n",
       "       (152, 332, 116, 5, 5. , 5. , 9.28, 1, 0.94),\n",
       "       (153, 321, 112, 5, 5. , 5. , 9.06, 1, 0.86),\n",
       "       (154, 324, 105, 3, 3. , 4. , 8.75, 0, 0.79),\n",
       "       (155, 326, 108, 3, 3. , 3.5, 8.89, 0, 0.8 ),\n",
       "       (156, 312, 109, 3, 3. , 3. , 8.69, 0, 0.77),\n",
       "       (157, 315, 105, 3, 2. , 2.5, 8.34, 0, 0.7 ),\n",
       "       (158, 309, 104, 2, 2. , 2.5, 8.26, 0, 0.65),\n",
       "       (159, 306, 106, 2, 2. , 2.5, 8.14, 0, 0.61),\n",
       "       (160, 297, 100, 1, 1.5, 2. , 7.9 , 0, 0.52),\n",
       "       (161, 315, 103, 1, 1.5, 2. , 7.86, 0, 0.57),\n",
       "       (162, 298,  99, 1, 1.5, 3. , 7.46, 0, 0.53),\n",
       "       (163, 318, 109, 3, 3. , 3. , 8.5 , 0, 0.67),\n",
       "       (164, 317, 105, 3, 3.5, 3. , 8.56, 0, 0.68),\n",
       "       (165, 329, 111, 4, 4.5, 4. , 9.01, 1, 0.81),\n",
       "       (166, 322, 110, 5, 4.5, 4. , 8.97, 0, 0.78),\n",
       "       (167, 302, 102, 3, 3.5, 5. , 8.33, 0, 0.65),\n",
       "       (168, 313, 102, 3, 2. , 3. , 8.27, 0, 0.64),\n",
       "       (169, 293,  97, 2, 2. , 4. , 7.8 , 1, 0.64),\n",
       "       (170, 311,  99, 2, 2.5, 3. , 7.98, 0, 0.65),\n",
       "       (171, 312, 101, 2, 2.5, 3.5, 8.04, 1, 0.68),\n",
       "       (172, 334, 117, 5, 4. , 4.5, 9.07, 1, 0.89),\n",
       "       (173, 322, 110, 4, 4. , 5. , 9.13, 1, 0.86),\n",
       "       (174, 323, 113, 4, 4. , 4.5, 9.23, 1, 0.89),\n",
       "       (175, 321, 111, 4, 4. , 4. , 8.97, 1, 0.87),\n",
       "       (176, 320, 111, 4, 4.5, 3.5, 8.87, 1, 0.85),\n",
       "       (177, 329, 119, 4, 4.5, 4.5, 9.16, 1, 0.9 ),\n",
       "       (178, 319, 110, 3, 3.5, 3.5, 9.04, 0, 0.82),\n",
       "       (179, 309, 108, 3, 2.5, 3. , 8.12, 0, 0.72),\n",
       "       (180, 307, 102, 3, 3. , 3. , 8.27, 0, 0.73),\n",
       "       (181, 300, 104, 3, 3.5, 3. , 8.16, 0, 0.71),\n",
       "       (182, 305, 107, 2, 2.5, 2.5, 8.42, 0, 0.71),\n",
       "       (183, 299, 100, 2, 3. , 3.5, 7.88, 0, 0.68),\n",
       "       (184, 314, 110, 3, 4. , 4. , 8.8 , 0, 0.75),\n",
       "       (185, 316, 106, 2, 2.5, 4. , 8.32, 0, 0.72),\n",
       "       (186, 327, 113, 4, 4.5, 4.5, 9.11, 1, 0.89),\n",
       "       (187, 317, 107, 3, 3.5, 3. , 8.68, 1, 0.84),\n",
       "       (188, 335, 118, 5, 4.5, 3.5, 9.44, 1, 0.93),\n",
       "       (189, 331, 115, 5, 4.5, 3.5, 9.36, 1, 0.93),\n",
       "       (190, 324, 112, 5, 5. , 5. , 9.08, 1, 0.88),\n",
       "       (191, 324, 111, 5, 4.5, 4. , 9.16, 1, 0.9 ),\n",
       "       (192, 323, 110, 5, 4. , 5. , 8.98, 1, 0.87),\n",
       "       (193, 322, 114, 5, 4.5, 4. , 8.94, 1, 0.86),\n",
       "       (194, 336, 118, 5, 4.5, 5. , 9.53, 1, 0.94),\n",
       "       (195, 316, 109, 3, 3.5, 3. , 8.76, 0, 0.77),\n",
       "       (196, 307, 107, 2, 3. , 3.5, 8.52, 1, 0.78),\n",
       "       (197, 306, 105, 2, 3. , 2.5, 8.26, 0, 0.73),\n",
       "       (198, 310, 106, 2, 3.5, 2.5, 8.33, 0, 0.73),\n",
       "       (199, 311, 104, 3, 4.5, 4.5, 8.43, 0, 0.7 ),\n",
       "       (200, 313, 107, 3, 4. , 4.5, 8.69, 0, 0.72),\n",
       "       (201, 317, 103, 3, 2.5, 3. , 8.54, 1, 0.73),\n",
       "       (202, 315, 110, 2, 3.5, 3. , 8.46, 1, 0.72),\n",
       "       (203, 340, 120, 5, 4.5, 4.5, 9.91, 1, 0.97),\n",
       "       (204, 334, 120, 5, 4. , 5. , 9.87, 1, 0.97),\n",
       "       (205, 298, 105, 3, 3.5, 4. , 8.54, 0, 0.69),\n",
       "       (206, 295,  99, 2, 2.5, 3. , 7.65, 0, 0.57),\n",
       "       (207, 315,  99, 2, 3.5, 3. , 7.89, 0, 0.63),\n",
       "       (208, 310, 102, 3, 3.5, 4. , 8.02, 1, 0.66),\n",
       "       (209, 305, 106, 2, 3. , 3. , 8.16, 0, 0.64),\n",
       "       (210, 301, 104, 3, 3.5, 4. , 8.12, 1, 0.68),\n",
       "       (211, 325, 108, 4, 4.5, 4. , 9.06, 1, 0.79),\n",
       "       (212, 328, 110, 4, 5. , 4. , 9.14, 1, 0.82),\n",
       "       (213, 338, 120, 4, 5. , 5. , 9.66, 1, 0.95),\n",
       "       (214, 333, 119, 5, 5. , 4.5, 9.78, 1, 0.96),\n",
       "       (215, 331, 117, 4, 4.5, 5. , 9.42, 1, 0.94),\n",
       "       (216, 330, 116, 5, 5. , 4.5, 9.36, 1, 0.93),\n",
       "       (217, 322, 112, 4, 4.5, 4.5, 9.26, 1, 0.91),\n",
       "       (218, 321, 109, 4, 4. , 4. , 9.13, 1, 0.85),\n",
       "       (219, 324, 110, 4, 3. , 3.5, 8.97, 1, 0.84),\n",
       "       (220, 312, 104, 3, 3.5, 3.5, 8.42, 0, 0.74),\n",
       "       (221, 313, 103, 3, 4. , 4. , 8.75, 0, 0.76),\n",
       "       (222, 316, 110, 3, 3.5, 4. , 8.56, 0, 0.75),\n",
       "       (223, 324, 113, 4, 4.5, 4. , 8.79, 0, 0.76),\n",
       "       (224, 308, 109, 2, 3. , 4. , 8.45, 0, 0.71),\n",
       "       (225, 305, 105, 2, 3. , 2. , 8.23, 0, 0.67),\n",
       "       (226, 296,  99, 2, 2.5, 2.5, 8.03, 0, 0.61),\n",
       "       (227, 306, 110, 2, 3.5, 4. , 8.45, 0, 0.63),\n",
       "       (228, 312, 110, 2, 3.5, 3. , 8.53, 0, 0.64),\n",
       "       (229, 318, 112, 3, 4. , 3.5, 8.67, 0, 0.71),\n",
       "       (230, 324, 111, 4, 3. , 3. , 9.01, 1, 0.82),\n",
       "       (231, 313, 104, 3, 4. , 4.5, 8.65, 0, 0.73),\n",
       "       (232, 319, 106, 3, 3.5, 2.5, 8.33, 1, 0.74),\n",
       "       (233, 312, 107, 2, 2.5, 3.5, 8.27, 0, 0.69),\n",
       "       (234, 304, 100, 2, 2.5, 3.5, 8.07, 0, 0.64),\n",
       "       (235, 330, 113, 5, 5. , 4. , 9.31, 1, 0.91),\n",
       "       (236, 326, 111, 5, 4.5, 4. , 9.23, 1, 0.88),\n",
       "       (237, 325, 112, 4, 4. , 4.5, 9.17, 1, 0.85),\n",
       "       (238, 329, 114, 5, 4.5, 5. , 9.19, 1, 0.86),\n",
       "       (239, 310, 104, 3, 2. , 3.5, 8.37, 0, 0.7 ),\n",
       "       (240, 299, 100, 1, 1.5, 2. , 7.89, 0, 0.59),\n",
       "       (241, 296, 101, 1, 2.5, 3. , 7.68, 0, 0.6 ),\n",
       "       (242, 317, 103, 2, 2.5, 2. , 8.15, 0, 0.65),\n",
       "       (243, 324, 115, 3, 3.5, 3. , 8.76, 1, 0.7 ),\n",
       "       (244, 325, 114, 3, 3.5, 3. , 9.04, 1, 0.76),\n",
       "       (245, 314, 107, 2, 2.5, 4. , 8.56, 0, 0.63),\n",
       "       (246, 328, 110, 4, 4. , 2.5, 9.02, 1, 0.81),\n",
       "       (247, 316, 105, 3, 3. , 3.5, 8.73, 0, 0.72),\n",
       "       (248, 311, 104, 2, 2.5, 3.5, 8.48, 0, 0.71),\n",
       "       (249, 324, 110, 3, 3.5, 4. , 8.87, 1, 0.8 ),\n",
       "       (250, 321, 111, 3, 3.5, 4. , 8.83, 1, 0.77),\n",
       "       (251, 320, 104, 3, 3. , 2.5, 8.57, 1, 0.74),\n",
       "       (252, 316,  99, 2, 2.5, 3. , 9.  , 0, 0.7 ),\n",
       "       (253, 318, 100, 2, 2.5, 3.5, 8.54, 1, 0.71),\n",
       "       (254, 335, 115, 4, 4.5, 4.5, 9.68, 1, 0.93),\n",
       "       (255, 321, 114, 4, 4. , 5. , 9.12, 0, 0.85),\n",
       "       (256, 307, 110, 4, 4. , 4.5, 8.37, 0, 0.79),\n",
       "       (257, 309,  99, 3, 4. , 4. , 8.56, 0, 0.76),\n",
       "       (258, 324, 100, 3, 4. , 5. , 8.64, 1, 0.78),\n",
       "       (259, 326, 102, 4, 5. , 5. , 8.76, 1, 0.77),\n",
       "       (260, 331, 119, 4, 5. , 4.5, 9.34, 1, 0.9 ),\n",
       "       (261, 327, 108, 5, 5. , 3.5, 9.13, 1, 0.87),\n",
       "       (262, 312, 104, 3, 3.5, 4. , 8.09, 0, 0.71),\n",
       "       (263, 308, 103, 2, 2.5, 4. , 8.36, 1, 0.7 ),\n",
       "       (264, 324, 111, 3, 2.5, 1.5, 8.79, 1, 0.7 ),\n",
       "       (265, 325, 110, 2, 3. , 2.5, 8.76, 1, 0.75),\n",
       "       (266, 313, 102, 3, 2.5, 2.5, 8.68, 0, 0.71),\n",
       "       (267, 312, 105, 2, 2. , 2.5, 8.45, 0, 0.72),\n",
       "       (268, 314, 107, 3, 3. , 3.5, 8.17, 1, 0.73),\n",
       "       (269, 327, 113, 4, 4.5, 5. , 9.14, 0, 0.83),\n",
       "       (270, 308, 108, 4, 4.5, 5. , 8.34, 0, 0.77),\n",
       "       (271, 306, 105, 2, 2.5, 3. , 8.22, 1, 0.72),\n",
       "       (272, 299,  96, 2, 1.5, 2. , 7.86, 0, 0.54),\n",
       "       (273, 294,  95, 1, 1.5, 1.5, 7.64, 0, 0.49),\n",
       "       (274, 312,  99, 1, 1. , 1.5, 8.01, 1, 0.52),\n",
       "       (275, 315, 100, 1, 2. , 2.5, 7.95, 0, 0.58),\n",
       "       (276, 322, 110, 3, 3.5, 3. , 8.96, 1, 0.78),\n",
       "       (277, 329, 113, 5, 5. , 4.5, 9.45, 1, 0.89),\n",
       "       (278, 320, 101, 2, 2.5, 3. , 8.62, 0, 0.7 ),\n",
       "       (279, 308, 103, 2, 3. , 3.5, 8.49, 0, 0.66),\n",
       "       (280, 304, 102, 2, 3. , 4. , 8.73, 0, 0.67),\n",
       "       (281, 311, 102, 3, 4.5, 4. , 8.64, 1, 0.68),\n",
       "       (282, 317, 110, 3, 4. , 4.5, 9.11, 1, 0.8 ),\n",
       "       (283, 312, 106, 3, 4. , 3.5, 8.79, 1, 0.81),\n",
       "       (284, 321, 111, 3, 2.5, 3. , 8.9 , 1, 0.8 ),\n",
       "       (285, 340, 112, 4, 5. , 4.5, 9.66, 1, 0.94),\n",
       "       (286, 331, 116, 5, 4. , 4. , 9.26, 1, 0.93),\n",
       "       (287, 336, 118, 5, 4.5, 4. , 9.19, 1, 0.92),\n",
       "       (288, 324, 114, 5, 5. , 4.5, 9.08, 1, 0.89),\n",
       "       (289, 314, 104, 4, 5. , 5. , 9.02, 0, 0.82),\n",
       "       (290, 313, 109, 3, 4. , 3.5, 9.  , 0, 0.79),\n",
       "       (291, 307, 105, 2, 2.5, 3. , 7.65, 0, 0.58),\n",
       "       (292, 300, 102, 2, 1.5, 2. , 7.87, 0, 0.56),\n",
       "       (293, 302,  99, 2, 1. , 2. , 7.97, 0, 0.56),\n",
       "       (294, 312,  98, 1, 3.5, 3. , 8.18, 1, 0.64),\n",
       "       (295, 316, 101, 2, 2.5, 2. , 8.32, 1, 0.61),\n",
       "       (296, 317, 100, 2, 3. , 2.5, 8.57, 0, 0.68),\n",
       "       (297, 310, 107, 3, 3.5, 3.5, 8.67, 0, 0.76),\n",
       "       (298, 320, 120, 3, 4. , 4.5, 9.11, 0, 0.86),\n",
       "       (299, 330, 114, 3, 4.5, 4.5, 9.24, 1, 0.9 ),\n",
       "       (300, 305, 112, 3, 3. , 3.5, 8.65, 0, 0.71),\n",
       "       (301, 309, 106, 2, 2.5, 2.5, 8.  , 0, 0.62),\n",
       "       (302, 319, 108, 2, 2.5, 3. , 8.76, 0, 0.66),\n",
       "       (303, 322, 105, 2, 3. , 3. , 8.45, 1, 0.65),\n",
       "       (304, 323, 107, 3, 3.5, 3.5, 8.55, 1, 0.73),\n",
       "       (305, 313, 106, 2, 2.5, 2. , 8.43, 0, 0.62),\n",
       "       (306, 321, 109, 3, 3.5, 3.5, 8.8 , 1, 0.74),\n",
       "       (307, 323, 110, 3, 4. , 3.5, 9.1 , 1, 0.79),\n",
       "       (308, 325, 112, 4, 4. , 4. , 9.  , 1, 0.8 ),\n",
       "       (309, 312, 108, 3, 3.5, 3. , 8.53, 0, 0.69),\n",
       "       (310, 308, 110, 4, 3.5, 3. , 8.6 , 0, 0.7 ),\n",
       "       (311, 320, 104, 3, 3. , 3.5, 8.74, 1, 0.76),\n",
       "       (312, 328, 108, 4, 4.5, 4. , 9.18, 1, 0.84),\n",
       "       (313, 311, 107, 4, 4.5, 4.5, 9.  , 1, 0.78),\n",
       "       (314, 301, 100, 3, 3.5, 3. , 8.04, 0, 0.67),\n",
       "       (315, 305, 105, 2, 3. , 4. , 8.13, 0, 0.66),\n",
       "       (316, 308, 104, 2, 2.5, 3. , 8.07, 0, 0.65),\n",
       "       (317, 298, 101, 2, 1.5, 2. , 7.86, 0, 0.54),\n",
       "       (318, 300,  99, 1, 1. , 2.5, 8.01, 0, 0.58),\n",
       "       (319, 324, 111, 3, 2.5, 2. , 8.8 , 1, 0.79),\n",
       "       (320, 327, 113, 4, 3.5, 3. , 8.69, 1, 0.8 ),\n",
       "       (321, 317, 106, 3, 4. , 3.5, 8.5 , 1, 0.75),\n",
       "       (322, 323, 104, 3, 4. , 4. , 8.44, 1, 0.73),\n",
       "       (323, 314, 107, 2, 2.5, 4. , 8.27, 0, 0.72),\n",
       "       (324, 305, 102, 2, 2. , 2.5, 8.18, 0, 0.62),\n",
       "       (325, 315, 104, 3, 3. , 2.5, 8.33, 0, 0.67),\n",
       "       (326, 326, 116, 3, 3.5, 4. , 9.14, 1, 0.81),\n",
       "       (327, 299, 100, 3, 2. , 2. , 8.02, 0, 0.63),\n",
       "       (328, 295, 101, 2, 2.5, 2. , 7.86, 0, 0.69),\n",
       "       (329, 324, 112, 4, 4. , 3.5, 8.77, 1, 0.8 ),\n",
       "       (330, 297,  96, 2, 2.5, 1.5, 7.89, 0, 0.43),\n",
       "       (331, 327, 113, 3, 3.5, 3. , 8.66, 1, 0.8 ),\n",
       "       (332, 311, 105, 2, 3. , 2. , 8.12, 1, 0.73),\n",
       "       (333, 308, 106, 3, 3.5, 2.5, 8.21, 1, 0.75),\n",
       "       (334, 319, 108, 3, 3. , 3.5, 8.54, 1, 0.71),\n",
       "       (335, 312, 107, 4, 4.5, 4. , 8.65, 1, 0.73),\n",
       "       (336, 325, 111, 4, 4. , 4.5, 9.11, 1, 0.83),\n",
       "       (337, 319, 110, 3, 3. , 2.5, 8.79, 0, 0.72),\n",
       "       (338, 332, 118, 5, 5. , 5. , 9.47, 1, 0.94),\n",
       "       (339, 323, 108, 5, 4. , 4. , 8.74, 1, 0.81),\n",
       "       (340, 324, 107, 5, 3.5, 4. , 8.66, 1, 0.81),\n",
       "       (341, 312, 107, 3, 3. , 3. , 8.46, 1, 0.75),\n",
       "       (342, 326, 110, 3, 3.5, 3.5, 8.76, 1, 0.79),\n",
       "       (343, 308, 106, 3, 3. , 3. , 8.24, 0, 0.58),\n",
       "       (344, 305, 103, 2, 2.5, 3.5, 8.13, 0, 0.59),\n",
       "       (345, 295,  96, 2, 1.5, 2. , 7.34, 0, 0.47),\n",
       "       (346, 316,  98, 1, 1.5, 2. , 7.43, 0, 0.49),\n",
       "       (347, 304,  97, 2, 1.5, 2. , 7.64, 0, 0.47),\n",
       "       (348, 299,  94, 1, 1. , 1. , 7.34, 0, 0.42),\n",
       "       (349, 302,  99, 1, 2. , 2. , 7.25, 0, 0.57),\n",
       "       (350, 313, 101, 3, 2.5, 3. , 8.04, 0, 0.62),\n",
       "       (351, 318, 107, 3, 3. , 3.5, 8.27, 1, 0.74),\n",
       "       (352, 325, 110, 4, 3.5, 4. , 8.67, 1, 0.73),\n",
       "       (353, 303, 100, 2, 3. , 3.5, 8.06, 1, 0.64),\n",
       "       (354, 300, 102, 3, 3.5, 2.5, 8.17, 0, 0.63),\n",
       "       (355, 297,  98, 2, 2.5, 3. , 7.67, 0, 0.59),\n",
       "       (356, 317, 106, 2, 2. , 3.5, 8.12, 0, 0.73),\n",
       "       (357, 327, 109, 3, 3.5, 4. , 8.77, 1, 0.79),\n",
       "       (358, 301, 104, 2, 3.5, 3.5, 7.89, 1, 0.68),\n",
       "       (359, 314, 105, 2, 2.5, 2. , 7.64, 0, 0.7 ),\n",
       "       (360, 321, 107, 2, 2. , 1.5, 8.44, 0, 0.81),\n",
       "       (361, 322, 110, 3, 4. , 5. , 8.64, 1, 0.85),\n",
       "       (362, 334, 116, 4, 4. , 3.5, 9.54, 1, 0.93),\n",
       "       (363, 338, 115, 5, 4.5, 5. , 9.23, 1, 0.91),\n",
       "       (364, 306, 103, 2, 2.5, 3. , 8.36, 0, 0.69),\n",
       "       (365, 313, 102, 3, 3.5, 4. , 8.9 , 1, 0.77),\n",
       "       (366, 330, 114, 4, 4.5, 3. , 9.17, 1, 0.86),\n",
       "       (367, 320, 104, 3, 3.5, 4.5, 8.34, 1, 0.74),\n",
       "       (368, 311,  98, 1, 1. , 2.5, 7.46, 0, 0.57),\n",
       "       (369, 298,  92, 1, 2. , 2. , 7.88, 0, 0.51),\n",
       "       (370, 301,  98, 1, 2. , 3. , 8.03, 1, 0.67),\n",
       "       (371, 310, 103, 2, 2.5, 2.5, 8.24, 0, 0.72),\n",
       "       (372, 324, 110, 3, 3.5, 3. , 9.22, 1, 0.89),\n",
       "       (373, 336, 119, 4, 4.5, 4. , 9.62, 1, 0.95),\n",
       "       (374, 321, 109, 3, 3. , 3. , 8.54, 1, 0.79),\n",
       "       (375, 315, 105, 2, 2. , 2.5, 7.65, 0, 0.39),\n",
       "       (376, 304, 101, 2, 2. , 2.5, 7.66, 0, 0.38),\n",
       "       (377, 297,  96, 2, 2.5, 2. , 7.43, 0, 0.34),\n",
       "       (378, 290, 100, 1, 1.5, 2. , 7.56, 0, 0.47),\n",
       "       (379, 303,  98, 1, 2. , 2.5, 7.65, 0, 0.56),\n",
       "       (380, 311,  99, 1, 2.5, 3. , 8.43, 1, 0.71),\n",
       "       (381, 322, 104, 3, 3.5, 4. , 8.84, 1, 0.78),\n",
       "       (382, 319, 105, 3, 3. , 3.5, 8.67, 1, 0.73),\n",
       "       (383, 324, 110, 4, 4.5, 4. , 9.15, 1, 0.82),\n",
       "       (384, 300, 100, 3, 3. , 3.5, 8.26, 0, 0.62),\n",
       "       (385, 340, 113, 4, 5. , 5. , 9.74, 1, 0.96),\n",
       "       (386, 335, 117, 5, 5. , 5. , 9.82, 1, 0.96),\n",
       "       (387, 302, 101, 2, 2.5, 3.5, 7.96, 0, 0.46),\n",
       "       (388, 307, 105, 2, 2. , 3.5, 8.1 , 0, 0.53),\n",
       "       (389, 296,  97, 2, 1.5, 2. , 7.8 , 0, 0.49),\n",
       "       (390, 320, 108, 3, 3.5, 4. , 8.44, 1, 0.76),\n",
       "       (391, 314, 102, 2, 2. , 2.5, 8.24, 0, 0.64),\n",
       "       (392, 318, 106, 3, 2. , 3. , 8.65, 0, 0.71),\n",
       "       (393, 326, 112, 4, 4. , 3.5, 9.12, 1, 0.84),\n",
       "       (394, 317, 104, 2, 3. , 3. , 8.76, 0, 0.77),\n",
       "       (395, 329, 111, 4, 4.5, 4. , 9.23, 1, 0.89),\n",
       "       (396, 324, 110, 3, 3.5, 3.5, 9.04, 1, 0.82),\n",
       "       (397, 325, 107, 3, 3. , 3.5, 9.11, 1, 0.84),\n",
       "       (398, 330, 116, 4, 5. , 4.5, 9.45, 1, 0.91),\n",
       "       (399, 312, 103, 3, 3.5, 4. , 8.78, 0, 0.67),\n",
       "       (400, 333, 117, 4, 5. , 4. , 9.66, 1, 0.95)],\n",
       "      dtype=[('Id', '<i8'), ('GRE_Dcore', '<i8'), ('TOEFL_Score', '<i8'), ('University_Rating', '<i8'), ('Sop', '<f8'), ('LOR', '<f8'), ('cGPA', '<f8'), ('reasch', '<i8'), ('change_of_admit', '<f8')])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission=np.genfromtxt('Admission_Predict-Copy1.csv',dtype=None,delimiter=\",\",skip_header=1,names=('Id',\"GRE_Dcore\",\"TOEFL Score\",\"University Rating\",\"Sop\",\"LOR\",\"cGPA\",\"reasch\",\"change_of_admit\"))\n",
    "graduate_admission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.65, 8.87, 8.  , 8.67, 8.21])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission[\"cGPA\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.544 , 1.4192, 1.28  , 1.3872, 1.3136, 1.4944, 1.312 , 1.264 ,\n",
       "       1.28  , 1.376 , 1.344 , 1.44  , 1.456 , 1.28  , 1.312 , 1.328 ,\n",
       "       1.392 , 1.28  , 1.408 , 1.36  , 1.264 , 1.344 , 1.52  , 1.552 ,\n",
       "       1.568 , 1.536 , 1.408 , 1.2   , 1.152 , 1.168 , 1.296 , 1.328 ,\n",
       "       1.504 , 1.536 , 1.568 , 1.472 , 1.344 , 1.248 , 1.2   , 1.232 ,\n",
       "       1.28  , 1.312 , 1.36  , 1.456 , 1.504 , 1.456 , 1.488 , 1.552 ,\n",
       "       1.416 , 1.344 , 1.328 , 1.264 , 1.28  , 1.296 , 1.28  , 1.232 ,\n",
       "       1.184 , 1.216 , 1.088 , 1.328 , 1.296 , 1.312 , 1.312 , 1.36  ,\n",
       "       1.392 , 1.4272, 1.4432, 1.3824, 1.4752, 1.4656, 1.5424, 1.5616,\n",
       "       1.512 , 1.4464, 1.424 , 1.3696, 1.3952, 1.3152, 1.2064, 1.1776,\n",
       "       1.2832, 1.52  , 1.4752, 1.4976, 1.512 , 1.3856, 1.3472, 1.3248,\n",
       "       1.3024, 1.4016, 1.2672, 1.2256, 1.2848, 1.2608, 1.2256, 1.2544,\n",
       "       1.28  , 1.4336, 1.4784, 1.4208, 1.3536, 1.2992, 1.32  , 1.3552,\n",
       "       1.448 , 1.4048, 1.4688, 1.5136, 1.5008, 1.3824, 1.3568, 1.3888,\n",
       "       1.3344, 1.3696, 1.352 , 1.4464, 1.3792, 1.1936, 1.1648, 1.4144,\n",
       "       1.5296, 1.5168, 1.3376, 1.3152, 1.3552, 1.3856, 1.4912, 1.3936,\n",
       "       1.456 , 1.496 , 1.5616, 1.384 , 1.3696, 1.4048, 1.4848, 1.4032,\n",
       "       1.352 , 1.3056, 1.4528, 1.4592, 1.464 , 1.4976, 1.5104, 1.5872,\n",
       "       1.4336, 1.3824, 1.3568, 1.4576, 1.568 , 1.3216, 1.5088, 1.4848,\n",
       "       1.4496, 1.4   , 1.4224, 1.3904, 1.3344, 1.3216, 1.3024, 1.264 ,\n",
       "       1.2576, 1.1936, 1.36  , 1.3696, 1.4416, 1.4352, 1.3328, 1.3232,\n",
       "       1.248 , 1.2768, 1.2864, 1.4512, 1.4608, 1.4768, 1.4352, 1.4192,\n",
       "       1.4656, 1.4464, 1.2992, 1.3232, 1.3056, 1.3472, 1.2608, 1.408 ,\n",
       "       1.3312, 1.4576, 1.3888, 1.5104, 1.4976, 1.4528, 1.4656, 1.4368,\n",
       "       1.4304, 1.5248, 1.4016, 1.3632, 1.3216, 1.3328, 1.3488, 1.3904,\n",
       "       1.3664, 1.3536, 1.5856, 1.5792, 1.3664, 1.224 , 1.2624, 1.2832,\n",
       "       1.3056, 1.2992, 1.4496, 1.4624, 1.5456, 1.5648, 1.5072, 1.4976,\n",
       "       1.4816, 1.4608, 1.4352, 1.3472, 1.4   , 1.3696, 1.4064, 1.352 ,\n",
       "       1.3168, 1.2848, 1.352 , 1.3648, 1.3872, 1.4416, 1.384 , 1.3328,\n",
       "       1.3232, 1.2912, 1.4896, 1.4768, 1.4672, 1.4704, 1.3392, 1.2624,\n",
       "       1.2288, 1.304 , 1.4016, 1.4464, 1.3696, 1.4432, 1.3968, 1.3568,\n",
       "       1.4192, 1.4128, 1.3712, 1.44  , 1.3664, 1.5488, 1.4592, 1.3392,\n",
       "       1.3696, 1.3824, 1.4016, 1.4944, 1.4608, 1.2944, 1.3376, 1.4064,\n",
       "       1.4016, 1.3888, 1.352 , 1.3072, 1.4624, 1.3344, 1.3152, 1.2576,\n",
       "       1.2224, 1.2816, 1.272 , 1.4336, 1.512 , 1.3792, 1.3584, 1.3968,\n",
       "       1.3824, 1.4576, 1.4064, 1.424 , 1.5456, 1.4816, 1.4704, 1.4528,\n",
       "       1.4432, 1.44  , 1.224 , 1.2592, 1.2752, 1.3088, 1.3312, 1.3712,\n",
       "       1.3872, 1.4576, 1.4784, 1.384 , 1.28  , 1.4016, 1.352 , 1.368 ,\n",
       "       1.3488, 1.408 , 1.456 , 1.44  , 1.3648, 1.376 , 1.3984, 1.4688,\n",
       "       1.44  , 1.2864, 1.3008, 1.2912, 1.2576, 1.2816, 1.408 , 1.3904,\n",
       "       1.36  , 1.3504, 1.3232, 1.3088, 1.3328, 1.4624, 1.2832, 1.2576,\n",
       "       1.4032, 1.2624, 1.3856, 1.2992, 1.3136, 1.3664, 1.384 , 1.4576,\n",
       "       1.4064, 1.5152, 1.3984, 1.3856, 1.3536, 1.4016, 1.3184, 1.3008,\n",
       "       1.1744, 1.1888, 1.2224, 1.1744, 1.16  , 1.2864, 1.3232, 1.3872,\n",
       "       1.2896, 1.3072, 1.2272, 1.2992, 1.4032, 1.2624, 1.2224, 1.3504,\n",
       "       1.3824, 1.5264, 1.4768, 1.3376, 1.424 , 1.4672, 1.3344, 1.1936,\n",
       "       1.2608, 1.2848, 1.3184, 1.4752, 1.5392, 1.3664, 1.224 , 1.2256,\n",
       "       1.1888, 1.2096, 1.224 , 1.3488, 1.4144, 1.3872, 1.464 , 1.3216,\n",
       "       1.5584, 1.5712, 1.2736, 1.296 , 1.248 , 1.3504, 1.3184, 1.384 ,\n",
       "       1.4592, 1.4016, 1.4768, 1.4464, 1.4576, 1.512 , 1.4048, 1.5456])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduate_admission[\"cGPA\"]=(graduate_admission[\"cGPA\"]*4/10)\n",
    "graduate_admission[\"cGPA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graduate_admission[graduate_admission[\"reasch\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328.7350427350427\n"
     ]
    }
   ],
   "source": [
    "print(graduate_admission[graduate_admission[\"change_of_admit\"]>0.8][\"GRE_Dcore\"].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
